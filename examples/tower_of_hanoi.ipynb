{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tower of Hanoi Example\n",
    "\n",
    "This [source](https://en.wikipedia.org/wiki/Tower_of_Hanoi) describes the puzzle called the **Tower of Hanoi** which is the focus of this value iteration example. In this puzzle, we have a number of pegs and a number of disks with different sizes. The puzzle starts with all disks on the leftmost peg in an order so that the bottom disk is the biggest and the disk sizes decrease until the top disk which is the smallest. The puzzle is considered solved when all disks are on the rightmost peg in order from biggest to smallest (bottom to top). Each action consists of moving a single disk from one peg to another. An action is only valid if the order of the disks is preserved so that a bigger disk cannot be placed on a smaller disk. \n",
    "\n",
    "We can model this puzzle as a Markov Decision Process (MDP) and then solve the optimal order of actions using value iteration! \n",
    "\n",
    "We can think of a state as the order of disks on each peg. The disks in order of biggest to largest for 4 disks is `[4, 3, 2, 1]`. An example state is `((1,), (2,), (4, 3))`. This means that on peg 0 (leftmost peg), there is the smallest disk - disk 1. On peg 1 (middle peg), there is disk 2. On peg 2 (rightmost peg), disk 4 is at the bottom and disk 3 is on top of it. An action is moving one disk from one peg to another. For example:\n",
    "- State: `((1,), (2,), (4, 3))`\n",
    "- Action: `'0->1'`\n",
    "- Next state: `((), (2, 1), (4, 3))`\n",
    "\n",
    "We need to add rewards to the system - we will state that on completing the puzzle you get a reward of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "To begin, we need to install the package `value_iteration` to use its functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install required packages\n",
    "! pip install git+https://github.com/CassandraDurr/value_iteration.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import the relevant packages for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "from value_iteration import ValueIteration, MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the MDP for the Tower of Hanoi\n",
    "Next, there is some work to be done in setting up the puzzle as an MDP. We first need a function that helps us set up all the states in the state space depending on the choice of the number of disks and the number of pegs. The function `generate_all_states` creates the state space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_states(num_disks: int = 4, num_pegs: int = 3) -> list[list[int]]:\n",
    "    \"\"\"Generate all valid Tower of Hanoi states with a given number of pegs and disks.\n",
    "    Each state is a list of pegs and each peg is a list of disks.\n",
    "    The list of disks are in strictly decreasing order (largest on bottom).\n",
    "\n",
    "    Args:\n",
    "        num_disks (int, optional): The number of disks. Defaults to 4.\n",
    "        num_pegs (int, optional): The number of pegs. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        list[list[int]]: list of states where a state is a list of disk-peg assignments.\n",
    "    \"\"\"\n",
    "    # Store states\n",
    "    states = []\n",
    "\n",
    "    # Get all assignments with form like: (0, 1, 2, 2)\n",
    "    # This means that disk 1 is on peg 0, disk 2 is on peg 1, disk 3 and 4 are on peg 2.\n",
    "    # Disk 1 is the smallest, disk 2 next smallest, ...\n",
    "    # Mathematically: assignment[i] = the peg where disk (i+1) should go\n",
    "\n",
    "    for assignment in product(range(num_pegs), repeat=num_disks):\n",
    "        # Use assignment to build (disk_number, assigned_peg) list in descending disk order\n",
    "        # We use descending order so it's easier to adhere to the Tower of Hanoi rules\n",
    "        # (biggest to smallest disk order)\n",
    "        disk_peg_pairs = [\n",
    "            (disk, assignment[disk - 1])\n",
    "            for disk in range(num_disks, 0, -1)  # For 4 disks -> 4, 3, 2, 1\n",
    "        ]\n",
    "        # For assignment (0, 1, 2, 2): [(4, 2), (3, 2), (2, 1), (1, 0)]\n",
    "        # Disk 4 is on peg 2, disk 3 in on peg 2, disk 2 is on peg 1 and disk 1 is on peg 0\n",
    "\n",
    "        # Build empty pegs storage to add disks to\n",
    "        pegs = [[] for _ in range(num_pegs)]\n",
    "\n",
    "        # Now place pegs using the disk-peg pairs\n",
    "        for disk, peg_index in disk_peg_pairs:\n",
    "            pegs[peg_index].append(disk)\n",
    "        # For the running example we expect: [[1], [2], [4, 3]]\n",
    "\n",
    "        # Add state to states\n",
    "        states.append(pegs)\n",
    "\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need some code that computes the list of legal actions to take from any given state. This will help us build the actions dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions_for_state(state: tuple[tuple[int]]) -> list[str]:\n",
    "    \"\"\"Given a state, return all of the valid actions in the form 'i->j'.\n",
    "\n",
    "    In notation 'i->j', we mean move the top element of peg i to peg j. The leftmost peg is '0'.\n",
    "\n",
    "    Example: state ((1,), (2,), (4, 3)) has possible actions ['0->1', '0->2', '1->2'].\n",
    "\n",
    "    Args:\n",
    "        state (tuple[tuple[int]]): Each sub-tuple represents a peg.\n",
    "            On each peg are disks represented by integers.\n",
    "            The order of integers represents the order on the peg from bottom to top.\n",
    "            Smaller disks are represented by smaller ints (1 is the smallest disk).\n",
    "\n",
    "    Returns:\n",
    "        list[str]: Valid actions to take in the state.\n",
    "    \"\"\"\n",
    "    # Store valid actions\n",
    "    actions = []\n",
    "\n",
    "    # Get the number of pegs from the state\n",
    "    num_pegs = len(state)\n",
    "\n",
    "    # Iterate over the source pegs ('i')\n",
    "    for i in range(num_pegs):\n",
    "\n",
    "        # Skip empty pegs with no disks\n",
    "        if not state[i]:\n",
    "            continue\n",
    "\n",
    "        # Get the top disk (should be the smallest on the peg)\n",
    "        # Pegs are ordered from biggest to smallest so take last element.\n",
    "        top_disk = state[i][-1]\n",
    "\n",
    "        # Iterate over the destination pegs ('j')\n",
    "        for j in range(num_pegs):\n",
    "\n",
    "            # Skip the action of not moving the disk ('i->i')\n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            # If the destination peg is empty or the current top disk is bigger than the candidate disk - this is a legal action.\n",
    "            if not state[j] or state[j][-1] > top_disk:\n",
    "                actions.append(f\"{i}->{j}\")\n",
    "\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function actually performs the action so that given a state and an action, the next state is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_action(state: tuple[tuple[int]], action_str: str) -> tuple[tuple[int]]:\n",
    "    \"\"\"Apply an action to a state and return the new state.\n",
    "    The action is moving the top disk from peg i to peg j.\n",
    "\n",
    "    Args:\n",
    "        state (tuple[tuple[int]]): The state representing the pegs and the disks on each peg.\n",
    "        action_str (str): 'i->j' - move disk from top of source peg i to destination peg j\n",
    "\n",
    "    Returns:\n",
    "        tuple[tuple[int]]: The new state after taking the action.\n",
    "    \"\"\"\n",
    "    # Action is in form \"i->j\"\n",
    "    # Get source peg and destination peg\n",
    "    i_str, j_str = action_str.split(\"->\")\n",
    "    i, j = int(i_str), int(j_str)\n",
    "\n",
    "    # Convert immutable state to a list to apply the action\n",
    "    pegs = [list(peg) for peg in state]\n",
    "    # Remove disk from source peg\n",
    "    disk = pegs[i].pop()\n",
    "    # Add disk to end of destimation peg (i.e. top position)\n",
    "    pegs[j].append(disk)\n",
    "\n",
    "    # Convert state back to tuples\n",
    "    return tuple(tuple(peg) for peg in pegs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above-mentioned helper functions, we can write another function to output the variables we need to model the MDP. This includes:\n",
    "- **S**: The list of states where a state is a complete configuration of the position of the disks on the pegs.\n",
    "- **A**: The actions dictionary - the keys of the dictionary are the valid states of the puzzle and the values are the actions which can be taken in each state.\n",
    "- **P**: The transition probability dictionary - each combination of `(current state, action, next state)` has an associated probability. In this case, because the system is deterministic, all probabilities have value 1.0.\n",
    "- **R**: The rewards dictionary - each combination of `(current state, action, next state)` has an associated reward. In this problem, all combinations where the next state is the goal state receives a reward. No other combinations of current state, action and next state receive rewards. This means there is a sparse reward structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tower_of_hanoi_mdp(\n",
    "    num_disks: int = 4, num_pegs: int = 3\n",
    ") -> tuple[list, dict, dict, dict]:\n",
    "    \"\"\"Returns S, A, P, R dictionaries for an Tower of Hanoi MDP.\n",
    "\n",
    "    Args:\n",
    "        num_disks (int, optional): The number of disks. Defaults to 4.\n",
    "        num_pegs (int, optional): The number of pegs. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        tuple[list, dict, dict, dict]: S, A, P, R variables - the MDP model for the Tower of Hanoi.\n",
    "    \"\"\"\n",
    "    # Generate all states\n",
    "    states_list = generate_all_states(num_disks, num_pegs)\n",
    "\n",
    "    # Convert to tuples since the states should not be modified\n",
    "    S = [tuple(tuple(peg) for peg in state) for state in states_list]\n",
    "\n",
    "    # Build action dictionary A for all states\n",
    "    A = {}\n",
    "    for s_key in S:\n",
    "        # Per state, list possible actions\n",
    "        A[s_key] = get_actions_for_state(s_key)\n",
    "\n",
    "    # Build transition probability matrix P for all states\n",
    "    P = {}\n",
    "    for s_key in S:\n",
    "        for action_str in A[s_key]:\n",
    "            # Get next state on taking an action\n",
    "            # The system is deterministic in the sense that when you move a disk, it goes where intended.\n",
    "            s_prime = apply_action(s_key, action_str)\n",
    "            P[(s_key, action_str, s_prime)] = 1.0\n",
    "\n",
    "    # Determine goal state for the rewards dictionary\n",
    "    # The goal is to move all disks to the last peg in order of biggest to smallest.\n",
    "    goal_list = [[] for _ in range(num_pegs)]\n",
    "    # The last peg needs to have entry descending disk sizes\n",
    "    goal_list[-1] = list(range(num_disks, 0, -1))  # e.g. [4, 3, 2, 1] for 4 disks\n",
    "    # Expecting a tuple\n",
    "    goal_state = tuple(tuple(peg) for peg in goal_list)\n",
    "\n",
    "    # Build rewards dictionary\n",
    "    # No rewards anywhere except final goal state which has a goal of 1\n",
    "    R = {}\n",
    "    for s_key, action_str, s_prime in P:\n",
    "        if s_prime == goal_state:\n",
    "            # Goal state reward\n",
    "            R[(s_key, action_str, s_prime)] = 1\n",
    "        else:\n",
    "            R[(s_key, action_str, s_prime)] = 0\n",
    "\n",
    "    return S, A, P, R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use the above function to build the MDP variables for a problem where there are 4 disks and 3 pegs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the MDP\n",
    "S, A, P, R = build_tower_of_hanoi_mdp(num_disks=4, num_pegs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of States: 81\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of States:\", len(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 81 states for this problem. \n",
    "\n",
    "## Value iteration to find the optimal policy\n",
    "\n",
    "Next, we compute the optimal policy and the optimal state values using the `ValueIteration` class, which performs synchronous value iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, max value change: 1.0\n",
      "Iteration 2, max value change: 0.95\n",
      "Iteration 3, max value change: 0.9025\n",
      "Iteration 4, max value change: 0.8573749999999999\n",
      "Iteration 5, max value change: 0.81450625\n",
      "Iteration 6, max value change: 0.7737809375\n",
      "Iteration 7, max value change: 0.7350918906249999\n",
      "Iteration 8, max value change: 0.69833729609375\n",
      "Iteration 9, max value change: 0.6634204312890624\n",
      "Iteration 10, max value change: 0.6302494097246092\n",
      "Iteration 11, max value change: 0.5987369392383788\n",
      "Iteration 12, max value change: 0.5688000922764598\n",
      "Iteration 13, max value change: 0.5403600876626369\n",
      "Iteration 14, max value change: 0.513342083279505\n",
      "Iteration 15, max value change: 0.4876749791155297\n",
      "Iteration 16, max value change: 0.4632912301597534\n",
      "Iteration 17, max value change: 0.44012666865176553\n",
      "Iteration 18, max value change: 0.41812033521917735\n",
      "Iteration 19, max value change: 0.39721431845821886\n",
      "Iteration 20, max value change: 0.37735360253530814\n",
      "Iteration 21, max value change: 0.3584859224085428\n",
      "Iteration 22, max value change: 0.3405616262881157\n",
      "Iteration 23, max value change: 0.32353354497371\n",
      "Iteration 24, max value change: 0.3073568677250247\n",
      "Iteration 25, max value change: 0.2919890243387733\n",
      "Iteration 26, max value change: 0.27738957312183476\n",
      "Iteration 27, max value change: 0.2635200944657434\n",
      "Iteration 28, max value change: 0.25034408974245537\n",
      "Iteration 29, max value change: 0.23782688525533313\n",
      "Iteration 30, max value change: 0.22593554099256696\n",
      "Iteration 31, max value change: 0.21463876394293901\n",
      "Iteration 32, max value change: 0.2039068257457921\n",
      "Iteration 33, max value change: 0.19371148445850261\n",
      "Iteration 34, max value change: 0.18402591023557768\n",
      "Iteration 35, max value change: 0.17482461472379862\n",
      "Iteration 36, max value change: 0.16608338398760836\n",
      "Iteration 37, max value change: 0.15777921478822776\n",
      "Iteration 38, max value change: 0.14989025404881673\n",
      "Iteration 39, max value change: 0.1423957413463759\n",
      "Iteration 40, max value change: 0.1352759542790576\n",
      "Iteration 41, max value change: 0.12851215656510506\n",
      "Iteration 42, max value change: 0.1220865487368501\n",
      "Iteration 43, max value change: 0.11598222130000746\n",
      "Iteration 44, max value change: 0.11018311023500704\n",
      "Iteration 45, max value change: 0.10467395472325691\n",
      "Iteration 46, max value change: 0.09944025698709424\n",
      "Iteration 47, max value change: 0.09446824413773935\n",
      "Iteration 48, max value change: 0.08974483193085181\n",
      "Iteration 49, max value change: 0.0852575903343098\n",
      "Iteration 50, max value change: 0.08099471081759457\n",
      "Iteration 51, max value change: 0.07694497527671462\n",
      "Iteration 52, max value change: 0.07309772651287894\n",
      "Iteration 53, max value change: 0.06944284018723401\n",
      "Iteration 54, max value change: 0.06597069817787293\n",
      "Iteration 55, max value change: 0.06267216326897884\n",
      "Iteration 56, max value change: 0.0595385551055303\n",
      "Iteration 57, max value change: 0.05656162735025383\n",
      "Iteration 58, max value change: 0.05373354598274105\n",
      "Iteration 59, max value change: 0.05104686868360364\n",
      "Iteration 60, max value change: 0.048494525249423326\n",
      "Iteration 61, max value change: 0.04606979898695229\n",
      "Iteration 62, max value change: 0.04376630903760592\n",
      "Iteration 63, max value change: 0.041577993585725004\n",
      "Iteration 64, max value change: 0.03949909390643924\n",
      "Iteration 65, max value change: 0.03752413921111675\n",
      "Iteration 66, max value change: 0.035647932250561176\n",
      "Iteration 67, max value change: 0.03386553563803307\n",
      "Iteration 68, max value change: 0.032172258856131286\n",
      "Iteration 69, max value change: 0.0305636459133245\n",
      "Iteration 70, max value change: 0.029035463617658408\n",
      "Iteration 71, max value change: 0.02758369043677611\n",
      "Iteration 72, max value change: 0.02620450591493828\n",
      "Iteration 73, max value change: 0.024894280619191633\n",
      "Iteration 74, max value change: 0.02364956658823214\n",
      "Iteration 75, max value change: 0.02246708825882049\n",
      "Iteration 76, max value change: 0.021343733845879953\n",
      "Iteration 77, max value change: 0.0202765471535864\n",
      "Iteration 78, max value change: 0.01926271979590677\n",
      "Iteration 79, max value change: 0.01829958380611174\n",
      "Iteration 80, max value change: 0.017384604615806154\n",
      "Iteration 81, max value change: 0.01651537438501549\n",
      "Iteration 82, max value change: 0.015689605665764716\n",
      "Iteration 83, max value change: 0.01490512538247657\n",
      "Iteration 84, max value change: 0.014159869113352208\n",
      "Iteration 85, max value change: 0.013451875657684909\n",
      "Iteration 86, max value change: 0.01277928187480093\n",
      "Iteration 87, max value change: 0.012140317781060617\n",
      "Iteration 88, max value change: 0.011533301892007408\n",
      "Iteration 89, max value change: 0.010956636797406993\n",
      "Iteration 90, max value change: 0.010408804957537043\n",
      "Iteration 91, max value change: 0.009888364709659925\n",
      "Iteration 92, max value change: 0.009393946474176573\n",
      "Iteration 93, max value change: 0.008924249150467745\n",
      "Iteration 94, max value change: 0.00847803669294489\n",
      "Iteration 95, max value change: 0.008054134858298312\n",
      "Iteration 96, max value change: 0.007651428115384107\n",
      "Iteration 97, max value change: 0.007268856709615079\n",
      "Iteration 98, max value change: 0.0069054138741346804\n",
      "Iteration 99, max value change: 0.006560143180427858\n",
      "Iteration 100, max value change: 0.006232136021406376\n",
      "Iteration 101, max value change: 0.00592052922033659\n",
      "Iteration 102, max value change: 0.005624502759319583\n",
      "Iteration 103, max value change: 0.005343277621353337\n",
      "Iteration 104, max value change: 0.005076113740285493\n",
      "Iteration 105, max value change: 0.004822308053271662\n",
      "Iteration 106, max value change: 0.004581192650608301\n",
      "Iteration 107, max value change: 0.0043521330180791296\n",
      "Iteration 108, max value change: 0.004134526367175262\n",
      "Iteration 109, max value change: 0.003927800048816543\n",
      "Iteration 110, max value change: 0.0037314100463756716\n",
      "Iteration 111, max value change: 0.0035448395440562663\n",
      "Iteration 112, max value change: 0.003367597566853675\n",
      "Iteration 113, max value change: 0.0031992176885102808\n",
      "Iteration 114, max value change: 0.0030392568040849\n",
      "Iteration 115, max value change: 0.002887293963880211\n",
      "Iteration 116, max value change: 0.0027429292656862003\n",
      "Iteration 117, max value change: 0.002605782802401535\n",
      "Iteration 118, max value change: 0.0024754936622812806\n",
      "Iteration 119, max value change: 0.0023517189791677495\n",
      "Iteration 120, max value change: 0.002234133030208696\n",
      "Iteration 121, max value change: 0.0021224263786994157\n",
      "Iteration 122, max value change: 0.002016305059764356\n",
      "Iteration 123, max value change: 0.0019154898067759163\n",
      "Iteration 124, max value change: 0.0018197153164365432\n",
      "Iteration 125, max value change: 0.0017287295506145384\n",
      "Iteration 126, max value change: 0.0016422930730843888\n",
      "Iteration 127, max value change: 0.0015601784194299029\n",
      "Iteration 128, max value change: 0.0014821694984590295\n",
      "Iteration 129, max value change: 0.001408061023536078\n",
      "Iteration 130, max value change: 0.0013376579723596294\n",
      "Iteration 131, max value change: 0.0012707750737419587\n",
      "Iteration 132, max value change: 0.0012072363200559266\n",
      "Iteration 133, max value change: 0.0011468745040534856\n",
      "Iteration 134, max value change: 0.0010895307788505448\n",
      "Iteration 135, max value change: 0.0010350542399075735\n",
      "Iteration 136, max value change: 0.0009833015279125945\n",
      "Iteration 137, max value change: 0.0009341364515167427\n",
      "Iteration 138, max value change: 0.00088742962894095\n",
      "Iteration 139, max value change: 0.0008430581474936361\n",
      "Iteration 140, max value change: 0.0008009052401192207\n",
      "Iteration 141, max value change: 0.0007608599781132597\n",
      "Iteration 142, max value change: 0.0007228169792075079\n",
      "Iteration 143, max value change: 0.000686676130246866\n",
      "Iteration 144, max value change: 0.0006523423237343451\n",
      "Iteration 145, max value change: 0.0006197252075477166\n",
      "Iteration 146, max value change: 0.0005887389471705973\n",
      "Iteration 147, max value change: 0.0005593019998126891\n",
      "Iteration 148, max value change: 0.0005313368998223211\n",
      "Iteration 149, max value change: 0.0005047700548308498\n",
      "Iteration 150, max value change: 0.0004795315520897958\n",
      "Iteration 151, max value change: 0.00045555497448557247\n",
      "Iteration 152, max value change: 0.0004327772257610718\n",
      "Iteration 153, max value change: 0.0004111383644733735\n",
      "Iteration 154, max value change: 0.0003905814462497048\n",
      "Iteration 155, max value change: 0.00037105237393753043\n",
      "Iteration 156, max value change: 0.000352499755241098\n",
      "Iteration 157, max value change: 0.0003348747674785102\n",
      "Iteration 158, max value change: 0.0003181310291040518\n",
      "Iteration 159, max value change: 0.0003022244776484939\n",
      "Iteration 160, max value change: 0.00028711325376562513\n",
      "Iteration 161, max value change: 0.00027275759107769915\n",
      "Iteration 162, max value change: 0.00025911971152403623\n",
      "Iteration 163, max value change: 0.0002461637259481009\n",
      "Iteration 164, max value change: 0.00023385553965127315\n",
      "Iteration 165, max value change: 0.00022216276266817658\n",
      "Iteration 166, max value change: 0.00021105462453441248\n",
      "Iteration 167, max value change: 0.00020050189330778068\n",
      "Iteration 168, max value change: 0.00019047679864225842\n",
      "Iteration 169, max value change: 0.00018095295871045636\n",
      "Iteration 170, max value change: 0.00017190531077559967\n",
      "Iteration 171, max value change: 0.00016331004523628678\n",
      "Iteration 172, max value change: 0.00015514454297438363\n",
      "Iteration 173, max value change: 0.00014738731582575326\n",
      "Iteration 174, max value change: 0.00014001795003437678\n",
      "Iteration 175, max value change: 0.00013301705253354612\n",
      "Iteration 176, max value change: 0.00012636619990757936\n",
      "Iteration 177, max value change: 0.00012004788991148985\n",
      "Iteration 178, max value change: 0.00011404549541627063\n",
      "Iteration 179, max value change: 0.00010834322064567914\n",
      "Iteration 180, max value change: 0.00010292605961303991\n",
      "Iteration 181, max value change: 9.7779756632832e-05\n",
      "Iteration 182, max value change: 9.289076880136804e-05\n",
      "Iteration 183, max value change: 8.824623036129964e-05\n",
      "Iteration 184, max value change: 8.383391884336788e-05\n",
      "Iteration 185, max value change: 7.964222290191003e-05\n",
      "Iteration 186, max value change: 7.566011175708098e-05\n",
      "Iteration 187, max value change: 7.18771061700707e-05\n",
      "Iteration 188, max value change: 6.828325086161158e-05\n",
      "Iteration 189, max value change: 6.486908831870863e-05\n",
      "Iteration 190, max value change: 6.162563390255116e-05\n",
      "Iteration 191, max value change: 5.854435220786769e-05\n",
      "Iteration 192, max value change: 5.561713459734108e-05\n",
      "Iteration 193, max value change: 5.283627786756284e-05\n",
      "Iteration 194, max value change: 5.019446397458438e-05\n",
      "Iteration 195, max value change: 4.76847407755443e-05\n",
      "Iteration 196, max value change: 4.530050373574568e-05\n",
      "Iteration 197, max value change: 4.303547854878076e-05\n",
      "Iteration 198, max value change: 4.08837046217414e-05\n",
      "Iteration 199, max value change: 3.88395193899882e-05\n",
      "Iteration 200, max value change: 3.6897543420622014e-05\n",
      "Iteration 201, max value change: 3.5052666249590914e-05\n",
      "Iteration 202, max value change: 3.330003293733341e-05\n",
      "Iteration 203, max value change: 3.163503129055556e-05\n",
      "Iteration 204, max value change: 3.005327972616101e-05\n",
      "Iteration 205, max value change: 2.8550615740030594e-05\n",
      "Iteration 206, max value change: 2.7123084953117882e-05\n",
      "Iteration 207, max value change: 2.5766930704662627e-05\n",
      "Iteration 208, max value change: 2.4478584169429496e-05\n",
      "Iteration 209, max value change: 2.3254654962556742e-05\n",
      "Iteration 210, max value change: 2.209192221425127e-05\n",
      "Iteration 211, max value change: 2.0987326103671933e-05\n",
      "Iteration 212, max value change: 1.993795979871038e-05\n",
      "Iteration 213, max value change: 1.894106180877486e-05\n",
      "Iteration 214, max value change: 1.7994008717714394e-05\n",
      "Iteration 215, max value change: 1.7094308282672444e-05\n",
      "Iteration 216, max value change: 1.6239592868672048e-05\n",
      "Iteration 217, max value change: 1.5427613226037806e-05\n",
      "Iteration 218, max value change: 1.4656232564469462e-05\n",
      "Iteration 219, max value change: 1.392342093620158e-05\n",
      "Iteration 220, max value change: 1.3227249889169457e-05\n",
      "Iteration 221, max value change: 1.2565887394622166e-05\n",
      "Iteration 222, max value change: 1.193759302520192e-05\n",
      "Iteration 223, max value change: 1.1340713374607958e-05\n",
      "Iteration 224, max value change: 1.0773677705522289e-05\n",
      "Iteration 225, max value change: 1.0234993820468219e-05\n",
      "Iteration 226, max value change: 9.72324412895631e-06\n",
      "Iteration 227, max value change: 9.237081922464085e-06\n",
      "Iteration 228, max value change: 8.775227826163245e-06\n",
      "Iteration 229, max value change: 8.336466434499812e-06\n",
      "Iteration 230, max value change: 7.919643113751818e-06\n",
      "Iteration 231, max value change: 7.523660958241862e-06\n",
      "Iteration 232, max value change: 7.147477909974498e-06\n",
      "Iteration 233, max value change: 6.790104015053089e-06\n",
      "Iteration 234, max value change: 6.450598814211617e-06\n",
      "Iteration 235, max value change: 6.1280688736786715e-06\n",
      "Iteration 236, max value change: 5.821665430616463e-06\n",
      "Iteration 237, max value change: 5.530582159352093e-06\n",
      "Iteration 238, max value change: 5.254053051295671e-06\n",
      "Iteration 239, max value change: 4.991350398775296e-06\n",
      "Iteration 240, max value change: 4.741782878348033e-06\n",
      "Iteration 241, max value change: 4.50469373447504e-06\n",
      "Iteration 242, max value change: 4.279459048461831e-06\n",
      "Iteration 243, max value change: 4.065486096216375e-06\n",
      "Iteration 244, max value change: 3.862211790384151e-06\n",
      "Iteration 245, max value change: 3.669101200642899e-06\n",
      "Iteration 246, max value change: 3.4856461414989326e-06\n",
      "Iteration 247, max value change: 3.311363833802261e-06\n",
      "Iteration 248, max value change: 3.145795642645055e-06\n",
      "Iteration 249, max value change: 2.9885058605572112e-06\n",
      "Iteration 250, max value change: 2.83908056797344e-06\n",
      "Iteration 251, max value change: 2.6971265398856303e-06\n",
      "Iteration 252, max value change: 2.562270212891349e-06\n",
      "Iteration 253, max value change: 2.434156701980328e-06\n",
      "Iteration 254, max value change: 2.312448867058947e-06\n",
      "Iteration 255, max value change: 2.1968264238836355e-06\n",
      "Iteration 256, max value change: 2.0869851029559072e-06\n",
      "Iteration 257, max value change: 1.982635848385428e-06\n",
      "Iteration 258, max value change: 1.883504056721108e-06\n",
      "Iteration 259, max value change: 1.7893288539738705e-06\n",
      "Iteration 260, max value change: 1.6998624117192662e-06\n",
      "Iteration 261, max value change: 1.6148692907336226e-06\n",
      "Iteration 262, max value change: 1.5341258254863988e-06\n",
      "Iteration 263, max value change: 1.4574195343897145e-06\n",
      "Iteration 264, max value change: 1.384548557581411e-06\n",
      "Iteration 265, max value change: 1.315321129347069e-06\n",
      "Iteration 266, max value change: 1.2495550727464888e-06\n",
      "Iteration 267, max value change: 1.1870773191091644e-06\n",
      "Iteration 268, max value change: 1.127723453286933e-06\n",
      "Iteration 269, max value change: 1.071337280222906e-06\n",
      "Iteration 270, max value change: 1.0177704163893964e-06\n",
      "Iteration 271, max value change: 9.668818954366998e-07\n",
      "Iteration 272, max value change: 9.185378013754075e-07\n",
      "Iteration 273, max value change: 8.726109115286818e-07\n",
      "Iteration 274, max value change: 8.289803661298834e-07\n",
      "Iteration 275, max value change: 7.875313485783408e-07\n",
      "Iteration 276, max value change: 7.48154779905974e-07\n",
      "Iteration 277, max value change: 7.107470407774485e-07\n",
      "Iteration 278, max value change: 6.752096890494386e-07\n",
      "Iteration 279, max value change: 6.414492039752417e-07\n",
      "Iteration 280, max value change: 6.093767446202492e-07\n",
      "Iteration 281, max value change: 5.789079073892367e-07\n",
      "Iteration 282, max value change: 5.499625119753659e-07\n",
      "Iteration 283, max value change: 5.224643864210066e-07\n",
      "Iteration 284, max value change: 4.963411672775919e-07\n",
      "Iteration 285, max value change: 4.715241086472588e-07\n",
      "Iteration 286, max value change: 4.4794790365898507e-07\n",
      "Iteration 287, max value change: 4.255505086092626e-07\n",
      "Iteration 288, max value change: 4.042729830899816e-07\n",
      "Iteration 289, max value change: 3.84059333669029e-07\n",
      "Iteration 290, max value change: 3.648563673408489e-07\n",
      "Iteration 291, max value change: 3.4661354852971726e-07\n",
      "Iteration 292, max value change: 3.2928287119204924e-07\n",
      "Iteration 293, max value change: 3.1281872736599325e-07\n",
      "Iteration 294, max value change: 2.9717779170823633e-07\n",
      "Iteration 295, max value change: 2.823189024780959e-07\n",
      "Iteration 296, max value change: 2.682029576206446e-07\n",
      "Iteration 297, max value change: 2.54792809961657e-07\n",
      "Iteration 298, max value change: 2.4205316950798306e-07\n",
      "Iteration 299, max value change: 2.2995051107699283e-07\n",
      "Iteration 300, max value change: 2.1845298547873426e-07\n",
      "Iteration 301, max value change: 2.0753033602716187e-07\n",
      "Iteration 302, max value change: 1.971538194922573e-07\n",
      "Iteration 303, max value change: 1.8729612882850688e-07\n",
      "Iteration 304, max value change: 1.77931322120628e-07\n",
      "Iteration 305, max value change: 1.690347559701877e-07\n",
      "Iteration 306, max value change: 1.6058301799404262e-07\n",
      "Iteration 307, max value change: 1.525538673163851e-07\n",
      "Iteration 308, max value change: 1.4492617417261044e-07\n",
      "Iteration 309, max value change: 1.3767986484225503e-07\n",
      "Iteration 310, max value change: 1.3079587191100472e-07\n",
      "Iteration 311, max value change: 1.242560783154545e-07\n",
      "Iteration 312, max value change: 1.1804327471054421e-07\n",
      "Iteration 313, max value change: 1.1214111150792405e-07\n",
      "Iteration 314, max value change: 1.065340562433903e-07\n",
      "Iteration 315, max value change: 1.0120735360885647e-07\n",
      "Iteration 316, max value change: 9.614698459614601e-08\n",
      "Iteration 317, max value change: 9.133963541074763e-08\n",
      "Iteration 318, max value change: 8.677265306289428e-08\n",
      "Iteration 319, max value change: 8.24340204985674e-08\n",
      "Iteration 320, max value change: 7.831232018418177e-08\n",
      "Iteration 321, max value change: 7.439670390851916e-08\n",
      "Iteration 322, max value change: 7.067686880191104e-08\n",
      "Iteration 323, max value change: 6.714302536181549e-08\n",
      "Iteration 324, max value change: 6.378587436017824e-08\n",
      "Iteration 325, max value change: 6.059658108625854e-08\n",
      "Iteration 326, max value change: 5.7566752253990217e-08\n",
      "Iteration 327, max value change: 5.468841468569963e-08\n",
      "Iteration 328, max value change: 5.1953993995823566e-08\n",
      "Iteration 329, max value change: 4.9356294162805625e-08\n",
      "Iteration 330, max value change: 4.688847976552779e-08\n",
      "Iteration 331, max value change: 4.4544055555206796e-08\n",
      "Iteration 332, max value change: 4.2316854020896244e-08\n",
      "Iteration 333, max value change: 4.0201010520490854e-08\n",
      "Iteration 334, max value change: 3.8190959728012785e-08\n",
      "Iteration 335, max value change: 3.6281411652794304e-08\n",
      "Iteration 336, max value change: 3.446734098133675e-08\n",
      "Iteration 337, max value change: 3.2743974642812645e-08\n",
      "Iteration 338, max value change: 3.110677582185417e-08\n",
      "Iteration 339, max value change: 2.955143685312578e-08\n",
      "Iteration 340, max value change: 2.807386501046949e-08\n",
      "Iteration 341, max value change: 2.6670171848763857e-08\n",
      "Iteration 342, max value change: 2.5336664322139768e-08\n",
      "Iteration 343, max value change: 2.4069832349482567e-08\n",
      "Iteration 344, max value change: 2.286634082082628e-08\n",
      "Iteration 345, max value change: 2.1723024268283098e-08\n",
      "Iteration 346, max value change: 2.0636872655188654e-08\n",
      "Iteration 347, max value change: 1.9605029599745194e-08\n",
      "Iteration 348, max value change: 1.8624778164166855e-08\n",
      "Iteration 349, max value change: 1.769353907832283e-08\n",
      "Iteration 350, max value change: 1.680886185795316e-08\n",
      "Iteration 351, max value change: 1.596841858741982e-08\n",
      "Iteration 352, max value change: 1.516999770245775e-08\n",
      "Iteration 353, max value change: 1.441149777292594e-08\n",
      "Iteration 354, max value change: 1.3690923061915328e-08\n",
      "Iteration 355, max value change: 1.300637730849985e-08\n",
      "Iteration 356, max value change: 1.2356058398665937e-08\n",
      "Iteration 357, max value change: 1.1738255700777245e-08\n",
      "Iteration 358, max value change: 1.1151342960147304e-08\n",
      "Iteration 359, max value change: 1.0593776522682674e-08\n",
      "Iteration 360, max value change: 1.0064088229455592e-08\n",
      "Iteration 361, max value change: 9.560883640347129e-09\n",
      "Iteration 362, max value change: 9.08283936951193e-09\n",
      "Iteration 363, max value change: 8.628697756307702e-09\n",
      "Iteration 364, max value change: 8.197261536224687e-09\n",
      "Iteration 365, max value change: 7.787399169956188e-09\n",
      "Iteration 366, max value change: 7.398028856187011e-09\n",
      "Iteration 367, max value change: 7.0281274133776606e-09\n",
      "Iteration 368, max value change: 6.676721397980145e-09\n",
      "Iteration 369, max value change: 6.342885328081138e-09\n",
      "Iteration 370, max value change: 6.025741683401975e-09\n",
      "Iteration 371, max value change: 5.724454688049718e-09\n",
      "Iteration 372, max value change: 5.438232086873995e-09\n",
      "Iteration 373, max value change: 5.1663207045749004e-09\n",
      "Iteration 374, max value change: 4.9080046693461554e-09\n",
      "Iteration 375, max value change: 4.66260452469669e-09\n",
      "Iteration 376, max value change: 4.429473676736961e-09\n",
      "Iteration 377, max value change: 4.208000170535797e-09\n",
      "Iteration 378, max value change: 3.997600472871454e-09\n",
      "Iteration 379, max value change: 3.797721248588459e-09\n",
      "Iteration 380, max value change: 3.6078349197055104e-09\n",
      "Iteration 381, max value change: 3.427443218129156e-09\n",
      "Iteration 382, max value change: 3.256070968404856e-09\n",
      "Iteration 383, max value change: 3.093267864073823e-09\n",
      "Iteration 384, max value change: 2.938604914959342e-09\n",
      "Iteration 385, max value change: 2.79167444716677e-09\n",
      "Iteration 386, max value change: 2.6520909912619572e-09\n",
      "Iteration 387, max value change: 2.5194868413791482e-09\n",
      "Iteration 388, max value change: 2.3935129433994007e-09\n",
      "Iteration 389, max value change: 2.2738371185937467e-09\n",
      "Iteration 390, max value change: 2.1601449518016125e-09\n",
      "Iteration 391, max value change: 2.052137126895559e-09\n",
      "Iteration 392, max value change: 1.949530314959702e-09\n",
      "Iteration 393, max value change: 1.8520545097544527e-09\n",
      "Iteration 394, max value change: 1.759452139538098e-09\n",
      "Iteration 395, max value change: 1.6714789552452203e-09\n",
      "Iteration 396, max value change: 1.587905806843537e-09\n",
      "Iteration 397, max value change: 1.508510649728123e-09\n",
      "Iteration 398, max value change: 1.433084761970349e-09\n",
      "Iteration 399, max value change: 1.3614300797826218e-09\n",
      "Iteration 400, max value change: 1.2933591975183845e-09\n",
      "Iteration 401, max value change: 1.228691814958438e-09\n",
      "Iteration 402, max value change: 1.1672574018462e-09\n",
      "Iteration 403, max value change: 1.1088943097092852e-09\n",
      "Iteration 404, max value change: 1.0534488836810851e-09\n",
      "Iteration 405, max value change: 1.0007772388576086e-09\n",
      "Iteration 406, max value change: 9.507381548701233e-10\n"
     ]
    }
   ],
   "source": [
    "# Create MDP data class\n",
    "mdp = MDP(states=S, actions=A, probabilities=P, rewards=R)\n",
    "\n",
    "# Setup value iteration class\n",
    "value_itr = ValueIteration(mdp=mdp, gamma=0.95, theta=1e-9, printing=True)\n",
    "\n",
    "# Run value iteration algorithm\n",
    "optimal_values, optimal_policy = value_itr.value_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal State Values: {((4, 3, 2, 1), (), ()): 5.001794648331587, ((3, 2, 1), (4,), ()): 7.162433797289331, ((3, 2, 1), (), (4,)): 7.539403997146664, ((4, 2, 1), (3,), ()): 6.140891675232602, ((2, 1), (4, 3), ()): 5.001794648331587, ((2, 1), (3,), (4,)): 8.793589734789329, ((4, 2, 1), (), (3,)): 5.833847091470972, ((2, 1), (4,), (3,)): 5.001794648331587, ((2, 1), (), (4, 3)): 9.256410247146663, ((4, 3, 1), (2,), ()): 5.265046999194511, ((3, 1), (4, 2), ()): 6.140891675232602, ((3, 1), (2,), (4,)): 8.353910247146665, ((4, 1), (3, 2), ()): 6.804312106521665, ((1,), (4, 3, 2), ()): 5.265046999194511, ((1,), (3, 2), (4,)): 7.539403997146664, ((4, 1), (2,), (3,)): 5.001794648331587, ((1,), (4, 2), (3,)): 5.542154735994222, ((1,), (2,), (4, 3)): 9.74358973478933, ((4, 3, 1), (), (2,)): 5.542154735994222, ((3, 1), (4,), (2,)): 6.140891675232602, ((3, 1), (), (4, 2)): 7.936214734789331, ((4, 1), (3,), (2,)): 6.4640965011955815, ((1,), (4, 3), (2,)): 5.542154735994222, ((1,), (3,), (4, 2)): 7.539403997146664, ((4, 1), (), (3, 2)): 5.001794648331587, ((1,), (4,), (3, 2)): 5.265046999194511, ((1,), (), (4, 3, 2)): 10.256410247146663, ((4, 3, 2), (1,), ()): 5.265046999194511, ((3, 2), (4, 1), ()): 6.804312106521665, ((3, 2), (1,), (4,)): 7.539403997146664, ((4, 2), (3, 1), ()): 6.140891675232602, ((2,), (4, 3, 1), ()): 5.265046999194511, ((2,), (3, 1), (4,)): 8.353910247146665, ((4, 2), (1,), (3,)): 5.542154735994222, ((2,), (4, 1), (3,)): 5.001794648331587, ((2,), (1,), (4, 3)): 9.74358973478933, ((4, 3), (2, 1), ()): 5.001794648331587, ((3,), (4, 2, 1), ()): 6.140891675232602, ((3,), (2, 1), (4,)): 8.793589734789329, ((4,), (3, 2, 1), ()): 7.162433797289331, ((), (4, 3, 2, 1), ()): 5.001794648331587, ((), (3, 2, 1), (4,)): 7.539403997146664, ((4,), (2, 1), (3,)): 5.001794648331587, ((), (4, 2, 1), (3,)): 5.833847091470972, ((), (2, 1), (4, 3)): 9.256410247146663, ((4, 3), (1,), (2,)): 5.542154735994222, ((3,), (4, 1), (2,)): 6.4640965011955815, ((3,), (1,), (4, 2)): 7.539403997146664, ((4,), (3, 1), (2,)): 6.140891675232602, ((), (4, 3, 1), (2,)): 5.542154735994222, ((), (3, 1), (4, 2)): 7.936214734789331, ((4,), (1,), (3, 2)): 5.265046999194511, ((), (4, 1), (3, 2)): 5.001794648331587, ((), (1,), (4, 3, 2)): 10.256410247146663, ((4, 3, 2), (), (1,)): 5.001794648331587, ((3, 2), (4,), (1,)): 6.804312106521665, ((3, 2), (), (4, 1)): 7.936214734789331, ((4, 2), (3,), (1,)): 6.4640965011955815, ((2,), (4, 3), (1,)): 5.001794648331587, ((2,), (3,), (4, 1)): 8.353910247146665, ((4, 2), (), (3, 1)): 5.542154735994222, ((2,), (4,), (3, 1)): 5.265046999194511, ((2,), (), (4, 3, 1)): 9.256410247146663, ((4, 3), (2,), (1,)): 5.001794648331587, ((3,), (4, 2), (1,)): 6.4640965011955815, ((3,), (2,), (4, 1)): 8.353910247146665, ((4,), (3, 2), (1,)): 6.804312106521665, ((), (4, 3, 2), (1,)): 5.001794648331587, ((), (3, 2), (4, 1)): 7.936214734789331, ((4,), (2,), (3, 1)): 5.265046999194511, ((), (4, 2), (3, 1)): 5.542154735994222, ((), (2,), (4, 3, 1)): 9.256410247146663, ((4, 3), (), (2, 1)): 5.833847091470972, ((3,), (4,), (2, 1)): 6.140891675232602, ((3,), (), (4, 2, 1)): 7.539403997146664, ((4,), (3,), (2, 1)): 6.140891675232602, ((), (4, 3), (2, 1)): 5.833847091470972, ((), (3,), (4, 2, 1)): 7.539403997146664, ((4,), (), (3, 2, 1)): 5.001794648331587, ((), (4,), (3, 2, 1)): 5.001794648331587, ((), (), (4, 3, 2, 1)): 9.74358973478933}\n",
      "Optimal Policy: {((4, 3, 2, 1), (), ()): '0->1', ((3, 2, 1), (4,), ()): '1->2', ((3, 2, 1), (), (4,)): '0->2', ((4, 2, 1), (3,), ()): '0->2', ((2, 1), (4, 3), ()): '0->1', ((2, 1), (3,), (4,)): '1->2', ((4, 2, 1), (), (3,)): '2->1', ((2, 1), (4,), (3,)): '0->2', ((2, 1), (), (4, 3)): '0->1', ((4, 3, 1), (2,), ()): '1->2', ((3, 1), (4, 2), ()): '0->2', ((3, 1), (2,), (4,)): '0->1', ((4, 1), (3, 2), ()): '0->1', ((1,), (4, 3, 2), ()): '1->2', ((1,), (3, 2), (4,)): '0->2', ((4, 1), (2,), (3,)): '0->2', ((1,), (4, 2), (3,)): '0->1', ((1,), (2,), (4, 3)): '1->2', ((4, 3, 1), (), (2,)): '0->2', ((3, 1), (4,), (2,)): '0->1', ((3, 1), (), (4, 2)): '2->1', ((4, 1), (3,), (2,)): '2->1', ((1,), (4, 3), (2,)): '0->2', ((1,), (3,), (4, 2)): '0->1', ((4, 1), (), (3, 2)): '0->1', ((1,), (4,), (3, 2)): '2->1', ((1,), (), (4, 3, 2)): '0->2', ((4, 3, 2), (1,), ()): '0->2', ((3, 2), (4, 1), ()): '1->0', ((3, 2), (1,), (4,)): '1->2', ((4, 2), (3, 1), ()): '1->2', ((2,), (4, 3, 1), ()): '0->2', ((2,), (3, 1), (4,)): '1->0', ((4, 2), (1,), (3,)): '1->0', ((2,), (4, 1), (3,)): '1->2', ((2,), (1,), (4, 3)): '0->2', ((4, 3), (2, 1), ()): '1->0', ((3,), (4, 2, 1), ()): '1->2', ((3,), (2, 1), (4,)): '0->2', ((4,), (3, 2, 1), ()): '0->2', ((), (4, 3, 2, 1), ()): '1->0', ((), (3, 2, 1), (4,)): '1->2', ((4,), (2, 1), (3,)): '1->2', ((), (4, 2, 1), (3,)): '2->0', ((), (2, 1), (4, 3)): '1->0', ((4, 3), (1,), (2,)): '1->2', ((3,), (4, 1), (2,)): '2->0', ((3,), (1,), (4, 2)): '1->0', ((4,), (3, 1), (2,)): '1->0', ((), (4, 3, 1), (2,)): '1->2', ((), (3, 1), (4, 2)): '2->0', ((4,), (1,), (3, 2)): '2->0', ((), (4, 1), (3, 2)): '1->0', ((), (1,), (4, 3, 2)): '1->2', ((4, 3, 2), (), (1,)): '2->1', ((3, 2), (4,), (1,)): '2->0', ((3, 2), (), (4, 1)): '0->1', ((4, 2), (3,), (1,)): '0->1', ((2,), (4, 3), (1,)): '2->1', ((2,), (3,), (4, 1)): '2->0', ((4, 2), (), (3, 1)): '2->0', ((2,), (4,), (3, 1)): '0->1', ((2,), (), (4, 3, 1)): '2->1', ((4, 3), (2,), (1,)): '2->0', ((3,), (4, 2), (1,)): '1->0', ((3,), (2,), (4, 1)): '2->1', ((4,), (3, 2), (1,)): '2->1', ((), (4, 3, 2), (1,)): '2->0', ((), (3, 2), (4, 1)): '1->0', ((4,), (2,), (3, 1)): '1->0', ((), (4, 2), (3, 1)): '2->1', ((), (2,), (4, 3, 1)): '2->0', ((4, 3), (), (2, 1)): '0->1', ((3,), (4,), (2, 1)): '2->1', ((3,), (), (4, 2, 1)): '2->0', ((4,), (3,), (2, 1)): '2->0', ((), (4, 3), (2, 1)): '1->0', ((), (3,), (4, 2, 1)): '2->1', ((4,), (), (3, 2, 1)): '2->1', ((), (4,), (3, 2, 1)): '2->0', ((), (), (4, 3, 2, 1)): '2->0'}\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"Optimal State Values:\", optimal_values)\n",
    "print(\"Optimal Policy:\", optimal_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are so many states, we need a better representation of which actions to take to solve the puzzle. In the next sections, we show the optimal actions to take, according to the policy derived using value iteration, from the beginning state of the puzzle to the goal state. This [source](https://en.wikipedia.org/wiki/Tower_of_Hanoi) states that we need a minimum of $2^n -1$ actions to solve the puzzle where $n$ represents the number of disks. The number of disks we are using is 4 so we expect the best solution to have 15 or more steps to get to the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tower_state(state: tuple[tuple[int]]) -> None:\n",
    "    \"\"\"Print a Tower of Hanoi state to the terminal in a user-friendly format.\n",
    "\n",
    "    Args:\n",
    "        state (tuple[tuple[int]]): Each sub-tuple represents a peg.\n",
    "            On each peg are disks represented by integers.\n",
    "            The order of integers represents the order on the peg from bottom to top.\n",
    "            Smaller disks are represented by smaller ints (1 is the smallest disk).\n",
    "    \"\"\"\n",
    "    # Get the labels for the pegs (i.e. '0', '1',...)\n",
    "    peg_labels = [str(i) for i in range(len(state))]\n",
    "\n",
    "    for peg_index, peg_contents in enumerate(state):\n",
    "        # Peg label\n",
    "        label = peg_labels[peg_index]\n",
    "\n",
    "        # Get content of which disks are on each peg\n",
    "        if peg_contents:\n",
    "            # Not empty peg (i.e. there are disks)\n",
    "            disk_str = \", \".join(str(disk) for disk in peg_contents)\n",
    "        else:\n",
    "            disk_str = \"(empty)\"\n",
    "\n",
    "        # Print peg label and contents\n",
    "        print(f\"  {label}: {disk_str}\")\n",
    "\n",
    "\n",
    "def show_tower_of_hanoi_plan(\n",
    "    policy: dict[tuple[tuple[int]], str],\n",
    "    start_state: tuple[tuple[int]],\n",
    "    goal_state: tuple[tuple[int]],\n",
    "    max_steps: int = 50,\n",
    ") -> None:\n",
    "    \"\"\"Given a policy, a start state and a goal state, print out each state and action recommended from the start state until either:\n",
    "        - the goal state is reached\n",
    "        - a maximum number of steps are taken\n",
    "\n",
    "    This function:\n",
    "      1. Prints the current state.\n",
    "      2. Prints the policy's best action for the current state.\n",
    "      3. Applies the best action to get the next state.\n",
    "      4. Repeat until:\n",
    "        - the goal state is reached\n",
    "        - OR a maximum number of steps are taken\n",
    "\n",
    "    Args:\n",
    "        policy (dict[tuple[tuple[int]], str]): A mapping of states to the best action to take in that state.\n",
    "        start_state (tuple[tuple[int]]): The beginning state of the puzzle.\n",
    "        goal_state (tuple[tuple[int]]): The end state of the puzzle.\n",
    "        max_steps (int, optional): The maximum number of steps to take until stopping. Defaults to 50.\n",
    "    \"\"\"\n",
    "    current_state = start_state\n",
    "    step = 0\n",
    "\n",
    "    while True:\n",
    "        # Increment steps\n",
    "        step += 1\n",
    "\n",
    "        # Print the step\n",
    "        print(f\"STEP {step}:\")\n",
    "\n",
    "        # Print current state\n",
    "        print(\"Current State:\")\n",
    "        print_tower_state(current_state)\n",
    "\n",
    "        # Check if the current state is not in the policy\n",
    "        if current_state not in policy:\n",
    "            print(\"No action defined for this state. Stopping.\")\n",
    "            break\n",
    "\n",
    "        # Get best action for current state\n",
    "        action = policy[current_state]\n",
    "        print(f\"Best Action: {action}\")\n",
    "\n",
    "        # Apply the action\n",
    "        next_state = apply_action(current_state, action)\n",
    "\n",
    "        # Barrier between steps for neatness\n",
    "        print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "        # Check if the goal is reached after the action\n",
    "        if next_state == goal_state:\n",
    "            print(\"Reached the goal state!\\n\")\n",
    "\n",
    "            # Print goal state\n",
    "            print_tower_state(goal_state)\n",
    "\n",
    "            # End loop\n",
    "            break\n",
    "\n",
    "        # Move to next state\n",
    "        current_state = next_state\n",
    "\n",
    "        # Check if the maximum number of steps are reached\n",
    "        if step >= max_steps:\n",
    "            print(f\"Reached {max_steps} steps without getting to goal. Stopping.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1:\n",
      "Current State:\n",
      "  0: 4, 3, 2, 1\n",
      "  1: (empty)\n",
      "  2: (empty)\n",
      "Best Action: 0->1\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 2:\n",
      "Current State:\n",
      "  0: 4, 3, 2\n",
      "  1: 1\n",
      "  2: (empty)\n",
      "Best Action: 0->2\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 3:\n",
      "Current State:\n",
      "  0: 4, 3\n",
      "  1: 1\n",
      "  2: 2\n",
      "Best Action: 1->2\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 4:\n",
      "Current State:\n",
      "  0: 4, 3\n",
      "  1: (empty)\n",
      "  2: 2, 1\n",
      "Best Action: 0->1\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 5:\n",
      "Current State:\n",
      "  0: 4\n",
      "  1: 3\n",
      "  2: 2, 1\n",
      "Best Action: 2->0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 6:\n",
      "Current State:\n",
      "  0: 4, 1\n",
      "  1: 3\n",
      "  2: 2\n",
      "Best Action: 2->1\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 7:\n",
      "Current State:\n",
      "  0: 4, 1\n",
      "  1: 3, 2\n",
      "  2: (empty)\n",
      "Best Action: 0->1\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 8:\n",
      "Current State:\n",
      "  0: 4\n",
      "  1: 3, 2, 1\n",
      "  2: (empty)\n",
      "Best Action: 0->2\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 9:\n",
      "Current State:\n",
      "  0: (empty)\n",
      "  1: 3, 2, 1\n",
      "  2: 4\n",
      "Best Action: 1->2\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 10:\n",
      "Current State:\n",
      "  0: (empty)\n",
      "  1: 3, 2\n",
      "  2: 4, 1\n",
      "Best Action: 1->0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 11:\n",
      "Current State:\n",
      "  0: 2\n",
      "  1: 3\n",
      "  2: 4, 1\n",
      "Best Action: 2->0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 12:\n",
      "Current State:\n",
      "  0: 2, 1\n",
      "  1: 3\n",
      "  2: 4\n",
      "Best Action: 1->2\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 13:\n",
      "Current State:\n",
      "  0: 2, 1\n",
      "  1: (empty)\n",
      "  2: 4, 3\n",
      "Best Action: 0->1\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 14:\n",
      "Current State:\n",
      "  0: 2\n",
      "  1: 1\n",
      "  2: 4, 3\n",
      "Best Action: 0->2\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "STEP 15:\n",
      "Current State:\n",
      "  0: (empty)\n",
      "  1: 1\n",
      "  2: 4, 3, 2\n",
      "Best Action: 1->2\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Reached the goal state!\n",
      "\n",
      "  0: (empty)\n",
      "  1: (empty)\n",
      "  2: 4, 3, 2, 1\n"
     ]
    }
   ],
   "source": [
    "start_state = ((4, 3, 2, 1), (), ())  # All disks on peg 0\n",
    "goal_state = ((), (), (4, 3, 2, 1))  # All disks on peg 2\n",
    "show_tower_of_hanoi_plan(\n",
    "    policy=optimal_policy,\n",
    "    start_state=start_state,\n",
    "    goal_state=goal_state,\n",
    "    max_steps=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reached the goal state by taking only 15 actions. This means that we have the true optimal solution since [source](https://en.wikipedia.org/wiki/Tower_of_Hanoi) stipulates that a minimum of 15 steps are required to solve the puzzle with 4 disks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "value_itr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
